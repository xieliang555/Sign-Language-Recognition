{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "INPUT_SIZE=(448,448)\n",
    "\n",
    "_default_anchors_setting = (\n",
    "    dict(layer='p3', stride=32, size=48, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    "    dict(layer='p4', stride=64, size=96, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    "    dict(layer='p5', stride=128, size=192, scale=[1, 2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
    ")\n",
    "\n",
    "\n",
    "def generate_default_anchor_maps(anchors_setting=None, input_shape=INPUT_SIZE):\n",
    "    \"\"\"\n",
    "    generate default anchor\n",
    "\n",
    "    :param anchors_setting: all informations of anchors\n",
    "    :param input_shape: shape of input images, e.g. (h, w)\n",
    "    :return: center_anchors: # anchors * 4 (oy, ox, h, w)\n",
    "             edge_anchors: # anchors * 4 (y0, x0, y1, x1)\n",
    "             anchor_area: # anchors * 1 (area)\n",
    "    \"\"\"\n",
    "    if anchors_setting is None:\n",
    "        anchors_setting = _default_anchors_setting\n",
    "\n",
    "    center_anchors = np.zeros((0, 4), dtype=np.float32)\n",
    "    edge_anchors = np.zeros((0, 4), dtype=np.float32)\n",
    "    anchor_areas = np.zeros((0,), dtype=np.float32)\n",
    "    input_shape = np.array(input_shape, dtype=int)\n",
    "\n",
    "    for anchor_info in anchors_setting:\n",
    "\n",
    "        stride = anchor_info['stride']\n",
    "        size = anchor_info['size']\n",
    "        scales = anchor_info['scale']\n",
    "        aspect_ratios = anchor_info['aspect_ratio']\n",
    "\n",
    "        output_map_shape = np.ceil(input_shape.astype(np.float32) / stride)\n",
    "        output_map_shape = output_map_shape.astype(np.int)\n",
    "        output_shape = tuple(output_map_shape) + (4,)\n",
    "        ostart = stride / 2.\n",
    "        oy = np.arange(ostart, ostart + stride * output_shape[0], stride)\n",
    "        oy = oy.reshape(output_shape[0], 1)\n",
    "        ox = np.arange(ostart, ostart + stride * output_shape[1], stride)\n",
    "        ox = ox.reshape(1, output_shape[1])\n",
    "        center_anchor_map_template = np.zeros(output_shape, dtype=np.float32)\n",
    "        center_anchor_map_template[:, :, 0] = oy\n",
    "        center_anchor_map_template[:, :, 1] = ox\n",
    "        for scale in scales:\n",
    "            for aspect_ratio in aspect_ratios:\n",
    "                center_anchor_map = center_anchor_map_template.copy()\n",
    "                center_anchor_map[:, :, 2] = size * scale / float(aspect_ratio) ** 0.5\n",
    "                center_anchor_map[:, :, 3] = size * scale * float(aspect_ratio) ** 0.5\n",
    "\n",
    "                edge_anchor_map = np.concatenate((center_anchor_map[..., :2] - center_anchor_map[..., 2:4] / 2.,\n",
    "                                                  center_anchor_map[..., :2] + center_anchor_map[..., 2:4] / 2.),\n",
    "                                                 axis=-1)\n",
    "                anchor_area_map = center_anchor_map[..., 2] * center_anchor_map[..., 3]\n",
    "                center_anchors = np.concatenate((center_anchors, center_anchor_map.reshape(-1, 4)))\n",
    "                edge_anchors = np.concatenate((edge_anchors, edge_anchor_map.reshape(-1, 4)))\n",
    "                anchor_areas = np.concatenate((anchor_areas, anchor_area_map.reshape(-1)))\n",
    "\n",
    "    return center_anchors, edge_anchors, anchor_areas\n",
    "\n",
    "\n",
    "center_anchors, edge_anchors, anchor_areas = generate_default_anchor_maps()\n",
    "print(generate_default_anchor_maps())\n",
    "print(center_anchors.shape)\n",
    "print(edge_anchors.shape)\n",
    "print(anchor_areas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1.]])\n",
      "tensor([[0., 0., 1.]])\n",
      "tensor([[0., 0., 0.]])\n",
      "tensor([2.6000])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from core import resnet\n",
    "import numpy as np\n",
    "from core.anchors import generate_default_anchor_maps, hard_nms\n",
    "from config import CAT_NUM, PROPOSAL_NUM\n",
    "from torchsummaryX import summary\n",
    "\n",
    "\n",
    "class ProposalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProposalNet, self).__init__()\n",
    "        self.down1 = nn.Conv2d(2048, 128, 3, 1, 1)\n",
    "        self.down2 = nn.Conv2d(128, 128, 3, 2, 1)\n",
    "        self.down3 = nn.Conv2d(128, 128, 3, 2, 1)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.tidy1 = nn.Conv2d(128, 6, 1, 1, 0)\n",
    "        self.tidy2 = nn.Conv2d(128, 6, 1, 1, 0)\n",
    "        self.tidy3 = nn.Conv2d(128, 9, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        d1 = self.ReLU(self.down1(x))\n",
    "        d2 = self.ReLU(self.down2(d1))\n",
    "        d3 = self.ReLU(self.down3(d2))\n",
    "        t1 = self.tidy1(d1).view(batch_size, -1)\n",
    "        t2 = self.tidy2(d2).view(batch_size, -1)\n",
    "        t3 = self.tidy3(d3).view(batch_size, -1)\n",
    "        return torch.cat((t1, t2, t3), dim=1)\n",
    "\n",
    "\n",
    "class attention_net(nn.Module):\n",
    "    def __init__(self, topN=4):\n",
    "        super(attention_net, self).__init__()\n",
    "        self.pretrained_model = resnet.resnet50(pretrained=True)\n",
    "        self.pretrained_model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.pretrained_model.fc = nn.Linear(512 * 4, 200)\n",
    "        self.proposal_net = ProposalNet()\n",
    "        self.topN = topN\n",
    "        self.concat_net = nn.Linear(2048 * (CAT_NUM + 1), 200)\n",
    "        self.partcls_net = nn.Linear(512 * 4, 200)\n",
    "        _, edge_anchors, _ = generate_default_anchor_maps()\n",
    "        self.pad_side = 224\n",
    "        self.edge_anchors = (edge_anchors + 224).astype(np.int)\n",
    "\n",
    "    def forward(self, x):\n",
    "        resnet_out, rpn_feature, feature = self.pretrained_model(x)\n",
    "        x_pad = F.pad(x, (self.pad_side, self.pad_side, self.pad_side, self.pad_side), mode='constant', value=0)\n",
    "        batch = x.size(0)\n",
    "        # we will reshape rpn to shape: batch * nb_anchor\n",
    "        rpn_score = self.proposal_net(rpn_feature.detach())\n",
    "        all_cdds = [\n",
    "            np.concatenate((x.reshape(-1, 1), self.edge_anchors.copy(), np.arange(0, len(x)).reshape(-1, 1)), axis=1)\n",
    "            for x in rpn_score.data.cpu().numpy()]\n",
    "        top_n_cdds = [hard_nms(x, topn=self.topN, iou_thresh=0.25) for x in all_cdds]\n",
    "        top_n_cdds = np.array(top_n_cdds)\n",
    "        top_n_index = top_n_cdds[:, :, -1].astype(np.int)\n",
    "        top_n_index = torch.from_numpy(top_n_index).cuda()\n",
    "        top_n_prob = torch.gather(rpn_score, dim=1, index=top_n_index)\n",
    "        part_imgs = torch.zeros([batch, self.topN, 3, 224, 224]).cuda()\n",
    "        for i in range(batch):\n",
    "            for j in range(self.topN):\n",
    "                [y0, x0, y1, x1] = top_n_cdds[i][j, 1:5].astype(np.int)\n",
    "                part_imgs[i:i + 1, j] = F.interpolate(x_pad[i:i + 1, :, y0:y1, x0:x1], size=(224, 224), mode='bilinear',\n",
    "                                                      align_corners=True)\n",
    "        part_imgs = part_imgs.view(batch * self.topN, 3, 224, 224)\n",
    "        _, _, part_features = self.pretrained_model(part_imgs.detach())\n",
    "        part_feature = part_features.view(batch, self.topN, -1)\n",
    "        part_feature = part_feature[:, :CAT_NUM, ...].contiguous()\n",
    "        part_feature = part_feature.view(batch, -1)\n",
    "        # concat_logits have the shape: B*200\n",
    "        concat_out = torch.cat([part_feature, feature], dim=1)\n",
    "        concat_logits = self.concat_net(concat_out)\n",
    "        raw_logits = resnet_out\n",
    "        # part_logits have the shape: B*N*200\n",
    "        part_logits = self.partcls_net(part_features).view(batch, self.topN, -1)\n",
    "        return [raw_logits, concat_logits, part_logits, top_n_index, top_n_prob]\n",
    "\n",
    "\n",
    "def list_loss(logits, targets):\n",
    "    temp = F.log_softmax(logits, -1)\n",
    "    loss = [-temp[i][targets[i].item()] for i in range(logits.size(0))]\n",
    "    return torch.stack(loss)\n",
    "\n",
    "# 1）理解hinge loss：大于1后loss为0，因为没必要再计算loss，\n",
    "# 2）score是排好序的，\n",
    "# 3）对于targets，乱序loss为1，顺序loss为0，score作为放大因子\n",
    "def ranking_loss(score, targets, proposal_num=PROPOSAL_NUM):\n",
    "    loss = Variable(torch.zeros(1))\n",
    "    batch_size = score.size(0)\n",
    "    for i in range(proposal_num):\n",
    "        targets_p = (targets > targets[:, i].unsqueeze(1)).type(torch.FloatTensor)\n",
    "        print(targets_p)\n",
    "        pivot = score[:, i].unsqueeze(1)\n",
    "        \n",
    "        loss_p = (1 - pivot + score) * targets_p\n",
    "        loss_p = torch.sum(F.relu(loss_p))\n",
    "        loss += loss_p\n",
    "    return loss / batch_size\n",
    "\n",
    "\n",
    "# batch_size=1\n",
    "# proposalNum = 3\n",
    "# score is ranked\n",
    "score = torch.tensor([[0.3,0.2,0.1]])\n",
    "targets = torch.tensor([[0.4,0.6,0.7]])\n",
    "print(ranking_loss(score, targets, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_nms(cdds, topn=10, iou_thresh=0.25):\n",
    "    if not (type(cdds).__module__ == 'numpy' and len(cdds.shape) == 2 and cdds.shape[1] >= 5):\n",
    "        raise TypeError('edge_box_map should be N * 5+ ndarray')\n",
    "\n",
    "    cdds = cdds.copy()\n",
    "    indices = np.argsort(cdds[:, 0])\n",
    "    cdds = cdds[indices]\n",
    "    cdd_results = []\n",
    "\n",
    "    res = cdds\n",
    "\n",
    "    while res.any():\n",
    "        cdd = res[-1]\n",
    "        cdd_results.append(cdd)\n",
    "        if len(cdd_results) == topn:\n",
    "            return np.array(cdd_results)\n",
    "        res = res[:-1]\n",
    "\n",
    "        start_max = np.maximum(res[:, 1:3], cdd[1:3])\n",
    "        end_min = np.minimum(res[:, 3:5], cdd[3:5])\n",
    "        lengths = end_min - start_max\n",
    "        intersec_map = lengths[:, 0] * lengths[:, 1]\n",
    "        intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)] = 0\n",
    "        iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1]) * (res[:, 4] - res[:, 2]) + (cdd[3] - cdd[1]) * (\n",
    "            cdd[4] - cdd[2]) - intersec_map)\n",
    "        res = res[iou_map_cur < iou_thresh]\n",
    "\n",
    "    return np.array(cdd_results)\n",
    "\n",
    "\n",
    "a = hard_nms(np.array([\n",
    "    [0.4, 1, 10, 12, 20],\n",
    "    [0.5, 1, 11, 11, 20],\n",
    "    [0.55, 20, 30, 40, 50]\n",
    "]), topn=100, iou_thresh=0.4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:49:15\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%H:%M:%S\",time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sign]",
   "language": "python",
   "name": "conda-env-sign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
