{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data import Field\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from jiwer import wer\n",
    "\n",
    "from dataset import PhoenixDataset\n",
    "from models.fine_grained_cnn import list_loss, ranking_loss\n",
    "from models.fine_grained_cnn_rnn import Fine_grained_CNN_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------Load PhoenixDataset----------------------\n",
    "BSZ = 1\n",
    "FrameSize = 224\n",
    "root = '/mnt/data/public/datasets'\n",
    "PROPOSAL_NUM = 6\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(FrameSize, (0.8, 1)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "TRG = Field(sequential=True, use_vocab=True,\n",
    "            init_token=None, eos_token=None,\n",
    "            lower=True, tokenize='spacy',\n",
    "            tokenizer_language='de')\n",
    "\n",
    "csv_dir = os.path.join(root, 'phoenix2014-release/phoenix-2014-multisigner')\n",
    "csv_dir = os.path.join(csv_dir, 'annotations/manual/train.corpus.csv')\n",
    "csv_file = pd.read_csv(csv_dir)\n",
    "tgt_sents = [csv_file.iloc[i, 0].lower().split('|')[3].split()\n",
    "             for i in range(len(csv_file))]\n",
    "TRG.build_vocab(tgt_sents, min_freq=1)\n",
    "VocabSize = len(TRG.vocab)\n",
    "\n",
    "\n",
    "def my_collate(batch):\n",
    "    videos = [item['video'] for item in batch]\n",
    "    video_lens = torch.tensor([len(v) for v in videos])\n",
    "    videos = pad_sequence(videos, batch_first=True)\n",
    "\n",
    "    annotations = [item['annotation'].split() for item in batch]\n",
    "    anno_lens = torch.tensor([len(a) for a in annotations])\n",
    "    annotations = TRG.process(annotations)\n",
    "\n",
    "    return {'videos': videos, 'annotations': annotations,\n",
    "            'video_lens': video_lens, 'anno_lens': anno_lens}\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    PhoenixDataset(root, 'train', transform),\n",
    "    batch_size=BSZ, num_workers=BSZ, shuffle=True,\n",
    "    pin_memory=True, collate_fn=my_collate)\n",
    "\n",
    "dev_loader = DataLoader(\n",
    "    PhoenixDataset(root, 'dev', transform),\n",
    "    batch_size=BSZ, num_workers=BSZ, shuffle=False,\n",
    "    pin_memory=True, collate_fn=my_collate)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    PhoenixDataset(root, 'test', transform),\n",
    "    batch_size=BSZ, num_workers=BSZ, shuffle=False,\n",
    "    pin_memory=True, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------Define train-------------------------\n",
    "def train(net, train_loader, optimizer, criterion_ctc, criterion_cnn, epoch, writer):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    running_wer = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        inputs = batch['videos'].cuda()\n",
    "        targets = batch['annotations'].permute(1, 0).contiguous().cuda()\n",
    "        input_lens = batch['video_lens'].cuda()\n",
    "        target_lens = batch['anno_lens'].cuda()\n",
    "        n, t, c, h, w = inputs.size()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        raw_logits, concat_logits, part_logits, top_n_prob, outs = net(inputs)\n",
    "        cnn_targets = outs.max(-1)[1].permute(1, 0).contiguous().view(-1).data\n",
    "        loss_raw = criterion_cnn(raw_logits, cnn_targets)\n",
    "        loss_concat = criterion_cnn(concat_logits, cnn_targets)\n",
    "        # ?简化？\n",
    "        loss_partcls = criterion_cnn(\n",
    "            part_logits.view(n*t*PROPOSAL_NUM, -1),\n",
    "            cnn_targets.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1))\n",
    "        # ?简化\n",
    "        part_targets = list_loss(\n",
    "            part_logits.view(n*t*PROPOSAL_NUM, -1),\n",
    "            cnn_targets.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1)).view(n*t, PROPOSAL_NUM)\n",
    "        loss_rank = ranking_loss(top_n_prob, part_targets)\n",
    "        loss_ctc = criterion_ctc(outs, targets, input_lens, target_lens)\n",
    "        loss_total = loss_raw + loss_concat + loss_partcls + loss_rank + loss_ctc\n",
    "        loss_total.backward()\n",
    "\n",
    "        # ignore batch that lead gradient exploration\n",
    "        flag = False\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.grad != None and torch.isnan(param.grad).any():\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            print(batch_idx)\n",
    "            continue\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        outs = outs.max(-1)[1].permute(1, 0).contiguous().view(-1)\n",
    "        outs = ' '.join([TRG.vocab.itos[i]\n",
    "                         for i, _ in groupby(outs) if i != VocabSize])\n",
    "        targets = ' '.join([TRG.vocab.itos[i] for i in targets.view(-1)])\n",
    "        running_wer += wer(targets, outs, standardize=True)\n",
    "        running_loss += loss_total.item()\n",
    "\n",
    "        N = len(train_loader) // 10\n",
    "        if batch_idx % N == N-1:\n",
    "            writer.add_scalar('train loss',\n",
    "                              running_loss/N,\n",
    "                              epoch*len(train_loader)+batch_idx)\n",
    "            writer.add_scalar('train wer',\n",
    "                              running_wer/N,\n",
    "                              epoch*len(train_loader)+batch_idx)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_wer = 0.0\n",
    "\n",
    "\n",
    "# --------------------------Define dev-------------------------\n",
    "def dev(net, dev_loader, criterion_ctc, criterion_cnn, epoch, writer):\n",
    "    net.eval()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_wer = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dev_loader):\n",
    "            inputs = batch['videos'].cuda()\n",
    "            targets = batch['annotations'].permute(1, 0).contiguous().cuda()\n",
    "            input_lens = batch['video_lens'].cuda()\n",
    "            target_lens = batch['anno_lens'].cuda()\n",
    "            n, t, c, h, w = inputs.size()\n",
    "\n",
    "            raw_logits, concat_logits, part_logits, top_n_prob, outs = net(inputs)\n",
    "            cnn_targets = outs.max(-1)[1].permute(1, 0).contiguous().view(-1).data\n",
    "            loss_raw = criterion_cnn(raw_logits, cnn_targets)\n",
    "            loss_concat = criterion_cnn(concat_logits, cnn_targets)\n",
    "            # ?简化？\n",
    "            loss_partcls = criterion_cnn(\n",
    "                part_logits.view(n*t*PROPOSAL_NUM, -1),\n",
    "                cnn_targets.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1))\n",
    "            # ?简化\n",
    "            part_targets = list_loss(\n",
    "                part_logits.view(n*t*PROPOSAL_NUM,-1), \n",
    "                cnn_targets.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1)).view(n*t, PROPOSAL_NUM)\n",
    "            loss_rank = ranking_loss(top_n_prob, part_targets)\n",
    "            loss_ctc = criterion_ctc(outs, targets, input_lens, target_lens)\n",
    "            loss_total = loss_raw + loss_concat + loss_partcls + loss_rank + loss_ctc\n",
    "\n",
    "            outs = outs.max(-1)[1].permute(1, 0).contiguous().view(-1)\n",
    "            outs = ' '.join([TRG.vocab.itos[i]\n",
    "                             for i, _ in groupby(outs) if i != VocabSize])\n",
    "            targets = ' '.join([TRG.vocab.itos[i] for i in targets.view(-1)])\n",
    "            epoch_wer += wer(targets, outs, standardize=True)\n",
    "            epoch_loss += loss_total.item()\n",
    "\n",
    "    epoch_wer /= len(dev_loader)\n",
    "    epoch_loss /= len(dev_loader)\n",
    "    if writer:\n",
    "        writer.add_scalar('dev loss', epoch_loss, epoch)\n",
    "        writer.add_scalar('dev wer', epoch_wer, epoch)\n",
    "\n",
    "    return epoch_wer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xieliang/anaconda3/envs/sign/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# --------------------------train dev test-------------------------\n",
    "resume_training = False\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "LR = 1e-4\n",
    "WD = 1e-4\n",
    "save_root = '/home/xieliang/Data/sign-language-recognition'\n",
    "if resume_training:\n",
    "    save_dict = torch.load(os.path.join(\n",
    "        save_root, 'save/Fine_grained_CNN_RNN6.pth'))\n",
    "    start_epoch = save_dict['epoch']+1\n",
    "    best_dev_wer = save_dict['best dev wer']\n",
    "    net = save_dict['net'].cuda()\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_dev_wer = 2\n",
    "    net = Fine_grained_CNN_RNN(VocabSize).cuda()\n",
    "\n",
    "criterion_ctc = nn.CTCLoss(blank=VocabSize)\n",
    "criterion_cnn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR, weight_decay=WD)\n",
    "writer = SummaryWriter(os.path.join(\n",
    "    save_root, 'log/Fine_grained_CNN_RNN_CTC6'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([42, 426])\n",
      "(426, 4)\n",
      "torch.Size([45, 426])\n",
      "(426, 4)\n",
      "torch.Size([55, 426])\n",
      "(426, 4)\n",
      "torch.Size([45, 426])\n",
      "(426, 4)\n",
      "torch.Size([22, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([54, 426])\n",
      "(426, 4)\n",
      "torch.Size([15, 426])\n",
      "(426, 4)\n",
      "torch.Size([58, 426])\n",
      "(426, 4)\n",
      "torch.Size([23, 426])\n",
      "(426, 4)\n",
      "torch.Size([44, 426])\n",
      "(426, 4)\n",
      "torch.Size([20, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([44, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([37, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([47, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([49, 426])\n",
      "(426, 4)\n",
      "torch.Size([37, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([54, 426])\n",
      "(426, 4)\n",
      "torch.Size([57, 426])\n",
      "(426, 4)\n",
      "torch.Size([52, 426])\n",
      "(426, 4)\n",
      "torch.Size([48, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([58, 426])\n",
      "(426, 4)\n",
      "torch.Size([20, 426])\n",
      "(426, 4)\n",
      "torch.Size([52, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([31, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([25, 426])\n",
      "(426, 4)\n",
      "torch.Size([48, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([23, 426])\n",
      "(426, 4)\n",
      "torch.Size([37, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([25, 426])\n",
      "(426, 4)\n",
      "torch.Size([47, 426])\n",
      "(426, 4)\n",
      "torch.Size([45, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([33, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([52, 426])\n",
      "(426, 4)\n",
      "torch.Size([26, 426])\n",
      "(426, 4)\n",
      "torch.Size([51, 426])\n",
      "(426, 4)\n",
      "torch.Size([31, 426])\n",
      "(426, 4)\n",
      "torch.Size([22, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([52, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([42, 426])\n",
      "(426, 4)\n",
      "torch.Size([62, 426])\n",
      "(426, 4)\n",
      "torch.Size([33, 426])\n",
      "(426, 4)\n",
      "torch.Size([50, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([37, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([48, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([26, 426])\n",
      "(426, 4)\n",
      "torch.Size([42, 426])\n",
      "(426, 4)\n",
      "torch.Size([21, 426])\n",
      "(426, 4)\n",
      "torch.Size([31, 426])\n",
      "(426, 4)\n",
      "torch.Size([34, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([60, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([26, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([44, 426])\n",
      "(426, 4)\n",
      "torch.Size([57, 426])\n",
      "(426, 4)\n",
      "torch.Size([24, 426])\n",
      "(426, 4)\n",
      "torch.Size([24, 426])\n",
      "(426, 4)\n",
      "torch.Size([45, 426])\n",
      "(426, 4)\n",
      "torch.Size([54, 426])\n",
      "(426, 4)\n",
      "torch.Size([42, 426])\n",
      "(426, 4)\n",
      "torch.Size([45, 426])\n",
      "(426, 4)\n",
      "torch.Size([44, 426])\n",
      "(426, 4)\n",
      "torch.Size([43, 426])\n",
      "(426, 4)\n",
      "torch.Size([28, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([33, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([28, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([48, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([53, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([26, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([50, 426])\n",
      "(426, 4)\n",
      "torch.Size([33, 426])\n",
      "(426, 4)\n",
      "torch.Size([34, 426])\n",
      "(426, 4)\n",
      "torch.Size([44, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([48, 426])\n",
      "(426, 4)\n",
      "torch.Size([23, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([42, 426])\n",
      "(426, 4)\n",
      "torch.Size([23, 426])\n",
      "(426, 4)\n",
      "torch.Size([34, 426])\n",
      "(426, 4)\n",
      "torch.Size([26, 426])\n",
      "(426, 4)\n",
      "torch.Size([45, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([23, 426])\n",
      "(426, 4)\n",
      "torch.Size([24, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([35, 426])\n",
      "(426, 4)\n",
      "torch.Size([22, 426])\n",
      "(426, 4)\n",
      "torch.Size([28, 426])\n",
      "(426, 4)\n",
      "torch.Size([14, 426])\n",
      "(426, 4)\n",
      "torch.Size([58, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([48, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([34, 426])\n",
      "(426, 4)\n",
      "torch.Size([42, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([43, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([50, 426])\n",
      "(426, 4)\n",
      "torch.Size([34, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([22, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([13, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([22, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([58, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([26, 426])\n",
      "(426, 4)\n",
      "torch.Size([37, 426])\n",
      "(426, 4)\n",
      "torch.Size([47, 426])\n",
      "(426, 4)\n",
      "torch.Size([59, 426])\n",
      "(426, 4)\n",
      "torch.Size([47, 426])\n",
      "(426, 4)\n",
      "torch.Size([35, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([33, 426])\n",
      "(426, 4)\n",
      "torch.Size([61, 426])\n",
      "(426, 4)\n",
      "torch.Size([22, 426])\n",
      "(426, 4)\n",
      "torch.Size([37, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([20, 426])\n",
      "(426, 4)\n",
      "torch.Size([13, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([54, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([42, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([48, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([20, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([51, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([41, 426])\n",
      "(426, 4)\n",
      "torch.Size([19, 426])\n",
      "(426, 4)\n",
      "torch.Size([31, 426])\n",
      "(426, 4)\n",
      "torch.Size([21, 426])\n",
      "(426, 4)\n",
      "torch.Size([33, 426])\n",
      "(426, 4)\n",
      "torch.Size([25, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([42, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([43, 426])\n",
      "(426, 4)\n",
      "torch.Size([28, 426])\n",
      "(426, 4)\n",
      "torch.Size([43, 426])\n",
      "(426, 4)\n",
      "torch.Size([23, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([27, 426])\n",
      "(426, 4)\n",
      "torch.Size([44, 426])\n",
      "(426, 4)\n",
      "torch.Size([20, 426])\n",
      "(426, 4)\n",
      "torch.Size([20, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([31, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([59, 426])\n",
      "(426, 4)\n",
      "torch.Size([26, 426])\n",
      "(426, 4)\n",
      "torch.Size([45, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([32, 426])\n",
      "(426, 4)\n",
      "torch.Size([51, 426])\n",
      "(426, 4)\n",
      "torch.Size([20, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([28, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([29, 426])\n",
      "(426, 4)\n",
      "torch.Size([36, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([38, 426])\n",
      "(426, 4)\n",
      "torch.Size([18, 426])\n",
      "(426, 4)\n",
      "torch.Size([40, 426])\n",
      "(426, 4)\n",
      "torch.Size([37, 426])\n",
      "(426, 4)\n",
      "torch.Size([52, 426])\n",
      "(426, 4)\n",
      "torch.Size([26, 426])\n",
      "(426, 4)\n",
      "torch.Size([37, 426])\n",
      "(426, 4)\n",
      "torch.Size([31, 426])\n",
      "(426, 4)\n",
      "torch.Size([53, 426])\n",
      "(426, 4)\n",
      "torch.Size([17, 426])\n",
      "(426, 4)\n",
      "torch.Size([17, 426])\n",
      "(426, 4)\n",
      "torch.Size([51, 426])\n",
      "(426, 4)\n",
      "torch.Size([51, 426])\n",
      "(426, 4)\n",
      "torch.Size([30, 426])\n",
      "(426, 4)\n",
      "torch.Size([43, 426])\n",
      "(426, 4)\n",
      "torch.Size([11, 426])\n",
      "(426, 4)\n",
      "torch.Size([39, 426])\n",
      "(426, 4)\n",
      "torch.Size([31, 426])\n",
      "(426, 4)\n",
      "torch.Size([44, 426])\n",
      "(426, 4)\n",
      "torch.Size([23, 426])\n",
      "(426, 4)\n",
      "torch.Size([45, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([19, 426])\n",
      "(426, 4)\n",
      "torch.Size([46, 426])\n",
      "(426, 4)\n",
      "torch.Size([58, 426])\n",
      "(426, 4)\n",
      "torch.Size([55, 426])\n",
      "(426, 4)\n",
      "torch.Size([44, 426])\n",
      "(426, 4)\n",
      "torch.Size([57, 426])\n",
      "(426, 4)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, 1000):\n",
    "    train(net, train_loader, optimizer, criterion_ctc, criterion_cnn, epoch, writer)\n",
    "    dev_wer, dev_loss = dev(net, dev_loader, criterion_ctc, criterion_cnn, epoch, writer)\n",
    "    print(f'epoch: {epoch} | dev wer: {dev_wer} | dev loss: {dev_loss}')\n",
    "    \n",
    "    if dev_wer < best_dev_wer:\n",
    "        best_dev_wer = dev_wer\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'net': net,\n",
    "                    'dev wer': dev_wer,\n",
    "                    'dev loss': dev_loss,\n",
    "                    'best dev wer': best_dev_wer}, \n",
    "                   os.path.join(save_root, 'save/Fine_grained_CNN_RNN6.pth'))\n",
    "        print(f'model saved with best dev wer: {best_dev_wer} in epoch {epoch}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- io阻塞时间越短，batch_size 越大，gpu利用率越高（可以接近100%）\n",
    "- pytorch中optimizer是传参数引用\n",
    "- pytorch中fix参数两种方法\n",
    "    - params.requires_grad=False\n",
    "    - optimizer中仅传入需要优化的参数，相比第一种方法会计算不需要优化参数的梯度\n",
    "- 改进思路：\n",
    "    - 防止学习到噪声，减小过拟合：\n",
    "        - cnn_rnn_ctc使用weight-decay: wer从0.51降到0.43\n",
    "        - cnn_rnn_ctc在fc中使用dropout: wer没有从0.51降到0.42升到0.43？ optimizer的初始值？\n",
    "        - BN:\n",
    "    - 提取更好的特征：\n",
    "        - cnn_rnn_ctc中resnet代替alexnet：wer从0.6降到0.4\n",
    "        - fine-grained cnn: 过拟合更严重？\n",
    "    - trick\n",
    "        - learning schedule: 陷入局部最优后可以收敛到最优点 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sign]",
   "language": "python",
   "name": "conda-env-sign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
