{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummaryX import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import PhoenixFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSZ = 100\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "root = '/mnt/data/public/datasets'\n",
    "dataset = PhoenixFrame(root, transform)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "dev_size = int(len(dataset) * 0.1)\n",
    "test_size = len(dataset) - train_size - dev_size\n",
    "# ? 分了3中性\n",
    "train_set, dev_set, test_set = torch.utils.data.random_split(\n",
    "    dataset, (train_size, dev_size, test_size))\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=BSZ, shuffle=True,\n",
    "    num_workers=32, pin_memory=True)\n",
    "dev_loader = DataLoader(\n",
    "    dev_set, batch_size=BSZ, shuffle=True,\n",
    "    num_workers=32, pin_memory=True)\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=BSZ,shuffle=True,\n",
    "    num_workers=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6392\n",
      "799\n",
      "799\n",
      "CPU times: user 389 µs, sys: 186 µs, total: 575 µs\n",
      "Wall time: 369 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(dev_loader))\n",
    "print(len(test_loader))\n",
    "\n",
    "# for batch_idx, batch in enumerate(test_loader):\n",
    "#     print(batch['frame'].shape)\n",
    "#     print(batch['target'])\n",
    "    \n",
    "#     if batch_idx == 0:\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# print(model)\n",
    "# summary(model, torch.ones(1,3,224,224))\n",
    "\n",
    "in_features = model.fc.in_features\n",
    "model.fc=nn.Linear(in_features, 1232)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
    "writer = SummaryWriter('./log/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, device, criterion, optimizer, epoch, writer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        inputs = batch['frame'].to(device)\n",
    "        # target is already tensor?\n",
    "        targets = batch['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = outputs.max(-1)[1].eq(targets).sum().item()/len(targets)\n",
    "        running_acc += acc\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 500 == 499:\n",
    "            writer.add_scalar('train loss',\n",
    "                              running_loss/500,\n",
    "                              epoch*len(train_loader)+batch_idx)\n",
    "            writer.add_scalar('train acc',\n",
    "                              running_acc/500,\n",
    "                              epoch*len(train_loader)+batch_idx)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, dev_loader, device, criterion, epoch, writer):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dev_loader):\n",
    "            inputs = batch['frame'].to(device)\n",
    "            # target is already tensor?\n",
    "            targets = batch['target'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            acc = outputs.max(-1)[1].eq(targets).sum().item()/len(targets)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc +=acc\n",
    "            \n",
    "    epoch_loss /= len(dev_loader)\n",
    "    epoch_acc /= len(dev_loader)\n",
    "    if writer:\n",
    "        writer.add_scalar('dev loss', epoch_loss, epoch)\n",
    "        writer.add_scalar('dev acc', epoch_acc, epoch)\n",
    "    return epoch_loss, epoch_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpoch = 50\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(nEpoch):\n",
    "    %time train(model, train_loader, device, criterion, optimizer, epoch, writer)\n",
    "    val_loss, val_acc = val(model, dev_loader, device, criterion, epoch, writer)\n",
    "    print(f'epoch:{epoch} | val loss:{val_loss} | val acc:{val_acc}')\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model, './save/test.pth')\n",
    "        print(f'best model saved with val acc: {val_acc} in epoch {epoch}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# model_ft = torch.load('./save/Res18_Pretrained_Phoenix_FrameWise.pth').to(device)\n",
    "# test_loss, test_acc = val(model_ft, test_loader, device, criterion, epoch=0, writer=None)\n",
    "# print(f'test loss:{test_loss} | test acc:{test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size: 100, num_worker:32, pin_memory:True -> memory: 3753MB, gpu_utils: 0%,100%, cpu: 45%\n",
    "- batch_size: 40, num_worker:20, pin_memory:True ->memory: 1941MB, gpu_utils: 0%-100%, cpu: 92%\n",
    "- batch_size: 20, num_worker:20, pin_memory:True -> memory: 1359MB, gpu_utils: 80%-100%, cpu: 101%\n",
    "- batch_size: 10, num_worker:20, pin_memory:True -> memory: 1055MB, gpu_utils: 60%-80%, cpu: 110%\n",
    "- batch_size: 10, num_worker:10, pin_memory:True -> memory: 1055MB, gpu utils: 0%-90%, cpu: 94%\n",
    "- batch_size: 10, num_worker:5, pin_memory:True -> memory:1055MB, gpu utils: 0%-70%, cpu: 74.7%\n",
    "- batch_size: 5, num_worker:10, pin_memory:True -> memory:945MB, gpu utils: 30%-60%\n",
    "- batch_size: 1, num_worker:10, pin_memory:True -> memory: 831MB, gpu utils: 30%-40%, cpu: 108%\n",
    "- batch_size: 5, num_worker:5, pin_memory:True -> memory: 945MB, gpu utils: 40%-60%, cpu: 107%\n",
    "- batch_size: 1, num_worker:5, pin_memory:True -> memory: 831MB, gpu utils: 30%-40%, cpu: 116%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sign]",
   "language": "python",
   "name": "conda-env-sign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
